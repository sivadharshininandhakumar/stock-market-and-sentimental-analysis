# -*- coding: utf-8 -*-
"""Stock_Market_Sentimental_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rmLKldPBxBwybT0eKuanH8cP9uNQX1rO
"""

pip install vaderSentiment

import pandas as pd
import numpy as np
import re
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

df=pd.read_csv('/content/Combined_News_DJIA.csv',encoding='ISO-8859-1')

df.head()

train = df[df['Date'] < '20150101']
test = df[df['Date']>'20141231']

#Removing punctuations
data=train.iloc[:,2:27]
data.replace("[^a-zA-Z]"," ",regex=True,inplace=True)

#Rrenaming column names for ease of access
list1=[i for i in range(25)]
new_Index=[str(i) for i in list1]
data.columns=new_Index
data.head(5)

#converting headlines to lower case
for index in new_Index:
  data[index]=data[index].str.lower()
data.head(1)

' '.join(str(x) for x in data.iloc[1,0:25])

headlines = []
for row in range(0,len(data.index)):
  headlines.append(' '.join(str(x) for x in data.iloc[row,0:25]))

headlines[0]

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier

#implement BAG OF WORDS
countvector=CountVectorizer(ngram_range=(2,2))
traindataset=countvector.fit_transform(headlines)

#implement RandomForest Classifier
randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')
randomclassifier.fit(traindataset,train['Label'])

#predict for the test dataset
test_transform=[]
for row in range(0,len(test.index)):
  test_transform.append(' '.join(str(x) for x in test.iloc[row,2:27]))
test_dataset=countvector.transform(test_transform)
predictions=randomclassifier.predict(test_dataset)

matrix=confusion_matrix(test['Label'],predictions)
score=accuracy_score(test['Label'],predictions)
report=classification_report(test['Label'],predictions)

matrix

print("Accuracy Score: ",score)
print("Classification Report :\n",report)

analyzer=SentimentIntensityAnalyzer()

positive=[]
negative=[]
neutral=[]
for n in range(df.shape[0]):
  title= df.iloc[n,0]
  description=df.iloc[n,2]
  title_analyzed= analyzer.polarity_scores(title)
  description_analyzed = analyzer.polarity_scores(description)
  negative.append(((title_analyzed['neg'])+(description_analyzed['neg']))/2)
  neutral.append(((title_analyzed['neu'])+(description_analyzed['neu']))/2)
  positive.append(((title_analyzed['pos'])+(description_analyzed['pos']))/2)
df["Negative"] = negative
df["Neutral"] = neutral
df["Positive"] = positive

Close=pd.set_option('display.max_columns',None)
print(df.head())

print(df['Negative'].mean())
print(df['Neutral'].mean())
print(df['Positive'].mean())

import matplotlib.pyplot as plt
df['Label'].value_counts().sort_index().plot(kind='pie',title='Counts of Label ',figsize=(10,5))

df['Label'].value_counts().sort_index().plot(kind='bar',title='Counts of Label ',figsize=(10,5))

df['Label'].value_counts().sort_index().plot(kind='box',title='Counts of Label ',figsize=(10,5))

df['Label'].value_counts().sort_index().plot(kind='area',title='Counts of Label ',figsize=(10,5))

df['Label'].value_counts().sort_index().plot(kind='line',title='Counts of Label ',figsize=(10,5))